{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Siti Zulfia Nurrafie**\n",
        "**Sistem Telekomunikasi A**\n",
        "**2304936**"
      ],
      "metadata": {
        "id": "q4Re6wrNm9DS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Menghubungkan Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLUj7-CQfgtq",
        "outputId": "a5f7c5f3-558f-4d22-a4d1-6081832bd103"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Untuk mengizinkan Colab mengakses Google Drive agar file hasil scraping bisa langsung disimpan ke sana. Hasilya akan muncul link untuk autentikasi akun Google."
      ],
      "metadata": {
        "id": "oC-0jcqQkymX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Import Library**"
      ],
      "metadata": {
        "id": "8ttx7BB7loYJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "H_tnZ1b2Y4IJ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">Untuk mengaktifkan alat bantu atau library,\n",
        "\n",
        ">requests: untuk mengambil halaman web.\n",
        ">BeautifulSoup: untuk membaca dan mengekstrak data dari HTML.\n",
        ">pandas: untuk menyimpan data dalam bentuk tabel."
      ],
      "metadata": {
        "id": "kVkWaMbik-vJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Cek Koneksi ke Website**"
      ],
      "metadata": {
        "id": "hyuf5MKElsZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://books.toscrape.com/catalogue/category/books/fantasy_19/index.html'\n",
        "response = requests.get(url)\n",
        "print(f\"Response status code: {response.status_code}\")\n",
        "\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    print(\"BeautifulSoup object created successfully.\")\n",
        "else:\n",
        "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eradqkt8bMyZ",
        "outputId": "6425a5ee-4cdc-4edb-a2fc-b43cb6b599e4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response status code: 200\n",
            "BeautifulSoup object created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Kode di aras untuk memastikan halaman bisa diakses dan siap diolah. Jika status 200, berarti halaman berhasil diambil dan siap diproses"
      ],
      "metadata": {
        "id": "a1QpLt3VlMyE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Ambil Judul dan Harga Buku (Halaman Tunggal)**"
      ],
      "metadata": {
        "id": "ahL6tsHil0Iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books = soup.find_all('article', class_='product_pod')\n",
        "\n",
        "titles = []\n",
        "prices = []\n",
        "\n",
        "for book in books:\n",
        "    title = book.h3.a['title']\n",
        "    price = book.find('p', class_='price_color').text\n",
        "    titles.append(title)\n",
        "    prices.append(price)"
      ],
      "metadata": {
        "id": "kDGtgMojbuh8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">Untuk menyaring semua elemen buku dan mengambil judul serta harga. Hasilnya Data disimpan dalam dua list: titles dan prices."
      ],
      "metadata": {
        "id": "2vgkR9P_lYvr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Simpan ke CSV (Halaman Tunggal)**"
      ],
      "metadata": {
        "id": "7vV7Ye3JmEZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_books = pd.DataFrame({'Title': titles, 'Price': prices})\n",
        "df_books.to_csv('/content/drive/MyDrive/books.csv', index=False)\n",
        "print(\"Data exported to books.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-KoIGs5dYBf",
        "outputId": "c9b51a79-703f-4e62-d81b-79c4ce584469"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data exported to books.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Untuk mengubah list menjadi tabel dan menyimpannya ke Drive."
      ],
      "metadata": {
        "id": "_fMccQ9omIcL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MULTI PAGE**"
      ],
      "metadata": {
        "id": "Rw_zzp8Mg5il"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Scraping Banyak Halaman (Multi-page)**"
      ],
      "metadata": {
        "id": "RTrQs7V4mVRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titles = []\n",
        "prices = []"
      ],
      "metadata": {
        "id": "REBBbvrlhEyV"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for page in range(1, 6):\n",
        "    url = f'https://books.toscrape.com/catalogue/category/books/fantasy_19/page-{page}.html'\n",
        "    print(f\"Scraping page: {page}\")\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    books = soup.find_all('article', class_='product_pod')\n",
        "\n",
        "    for book in books:\n",
        "        title = book.h3.a['title']\n",
        "        price = book.find('p', class_='price_color').text\n",
        "        titles.append(title)\n",
        "        prices.append(price)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P13AEn1bhLv4",
        "outputId": "0b4ff8e7-3c52-4502-fe62-e404be423c97"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping page: 1\n",
            "Scraping page: 2\n",
            "Scraping page: 3\n",
            "Scraping page: 4\n",
            "Scraping page: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Untuk mengambil data dari 5 halaman secara berturut-turut, dengan catatam URl harus pakai f-string agar page berubah secara otomatis."
      ],
      "metadata": {
        "id": "g_xguFImmZXL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.Simpan ke CSV (Multi-page)**"
      ],
      "metadata": {
        "id": "wqaIIqCXmp_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame({'Title': titles, 'Price': prices})\n",
        "data.to_csv('/content/drive/MyDrive/books5page.csv', index=False)\n",
        "print(\"Data exported to books5page.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSqwnJOtiGS7",
        "outputId": "5861b760-197c-476e-9625-832070a8497f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data exported to books5page.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">Untuk menyimpan hasil scraping dari 5 halaman ke dalam file baru yaitu books5page.csv berisi data gabungan dari semua halaman."
      ],
      "metadata": {
        "id": "3oV8yi2Amty7"
      }
    }
  ]
}